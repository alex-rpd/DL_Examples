{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Keras and Shakespeares texts to create text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Dropout, GRU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('./data/shakespeare.txt', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {c:i for i, c in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = np.array(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_of_text = text.split('\\n')\n",
    "lengths_of_lines = [len(i) for i in lines_of_text if len(i)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the length of the each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(lengths_of_lines, kde=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46.365524692433695, 47.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(lengths_of_lines), np.median(lengths_of_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 120\n",
    "total_num_seq = len(text) // (seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose mi\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose mi"
     ]
    }
   ],
   "source": [
    "for i in char_dataset.take(100):\n",
    "    print(idx_to_char[i.numpy()], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    # input_text = seq[:-1]\n",
    "    # target_text = seq[1:]\n",
    "    return seq[:-1], seq[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "---\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    print(input_text.numpy())\n",
    "    print(\"\".join(idx_to_char[input_text.numpy()]))\n",
    "    print('---')\n",
    "    print(target_text.numpy())\n",
    "    print(\"\".join(idx_to_char[target_text.numpy()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 34  1 73 60 58 70 77 60 73  5 59  1 63 64 68  8  1 57 70 76 69 59  1\n",
      " 76 71  1 63 64 74  1 78 70 76 69 59  8  0  1  1  1  1 26 69 59  8  1 56\n",
      " 61 75 60 73  1 74 70 68 60  1 74 68 56 67 67  1 74 71 56 58 60  8  1 57\n",
      " 60 64 69 62  1 74 75 73 70 69 62  1 56 75  1 63 60 56 73 75  8  0  1  1\n",
      "  1  1 33 60  1 74 60 69 75  1 68 60  1 63 64 75 63 60 73  8  1 74 75 73]\n",
      " I recover'd him, bound up his wound,\n",
      "    And, after some small space, being strong at heart,\n",
      "    He sent me hither, str\n",
      "---\n",
      "[34  1 73 60 58 70 77 60 73  5 59  1 63 64 68  8  1 57 70 76 69 59  1 76\n",
      " 71  1 63 64 74  1 78 70 76 69 59  8  0  1  1  1  1 26 69 59  8  1 56 61\n",
      " 75 60 73  1 74 70 68 60  1 74 68 56 67 67  1 74 71 56 58 60  8  1 57 60\n",
      " 64 69 62  1 74 75 73 70 69 62  1 56 75  1 63 60 56 73 75  8  0  1  1  1\n",
      "  1 33 60  1 74 60 69 75  1 68 60  1 63 64 75 63 60 73  8  1 74 75 73 56]\n",
      "I recover'd him, bound up his wound,\n",
      "    And, after some small space, being strong at heart,\n",
      "    He sent me hither, stra\n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    print(input_text.numpy()[0])\n",
    "    print(\"\".join(idx_to_char[input_text.numpy()[0]]))\n",
    "    print('---')\n",
    "    print(target_text.numpy()[0])\n",
    "    print(\"\".join(idx_to_char[target_text.numpy()[0]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dimensions = 64\n",
    "rnn_neurons = 1026\n",
    "vocabulary_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true=y_true, y_pred=y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim,\n",
    "                        batch_input_shape=[batch_size, None]))\n",
    "\n",
    "    model.add(GRU(rnn_neurons, return_sequences=True, stateful=True,\n",
    "                  recurrent_initializer='glorot_uniform'))\n",
    "\n",
    "    model.add(Dense(vocab_size))\n",
    "\n",
    "    model.compile(optimizer='adam', loss=sparse_cat_loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size=vocabulary_size,\n",
    "                     embed_dim=embed_dimensions,\n",
    "                     rnn_neurons=rnn_neurons,\n",
    "                     batch_size=batch_size)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 25/351 [=>............................] - ETA: 23s - loss: 4.2514"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": " [_Derived_]RecvAsync is cancelled.\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_27}}]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_24]] [Op:__inference_train_function_2598]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-51fded4b19d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# with tf.device('/device:gpu:0'):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexrpd\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mCancelledError\u001b[0m:  [_Derived_]RecvAsync is cancelled.\n\t [[{{node Adam/Adam/update/AssignSubVariableOp/_27}}]]\n\t [[gradient_tape/sequential/embedding/embedding_lookup/Reshape/_24]] [Op:__inference_train_function_2598]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "# with tf.device('/device:gpu:0'):\n",
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some predicted text before training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for input_example_batch, target_example_batch in dataset.take(1):\n",
    "#     example_batch_pred = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
